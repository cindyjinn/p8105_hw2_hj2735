---
title: "p8105_hw2_hj2735"
author: "cindyjin"
date: "2025-09-30"
output: github_document
---

### Problem 1 

```{r Problem 1}
library(tidyverse)

# Load CSV from the data/ subdirectory
pols_month = read_csv("data/fivethirtyeight_datasets/pols-month.csv")
unemployment = read_csv("data/fivethirtyeight_datasets/unemployment.csv")
snp = read_csv("data/fivethirtyeight_datasets/snp.csv")
```

```{r}
pols_month = pols_month |>
  separate(mon, into = c("year", "month", "day"), sep = "-", convert = TRUE) |>
  mutate(
    month     = factor(month.name[month], levels = month.name),   # replace number with month name
    president = if_else(prez_gop == 1, "gop", "dem")              # create president variable
  ) |>
  select(year, month, everything(), -prez_dem, -prez_gop, -day) |>  # remove prez_dem, prez_gop, day
  arrange(year, month)

# Preview cleaned data
glimpse(pols_month)
head(pols_month)
```

```{r}
# Clean snp data
snp = snp |>
  separate(date, into = c("month", "day", "year"), sep = "/", convert = TRUE) |>
  mutate(
    # Convert 2-digit year to 4-digit year
    year = if_else(year < 50, year + 2000, year + 1900),
    month = factor(month.name[month], levels = month.name)
  ) |>
  select(year, month, everything(), -day) |>
  arrange(year, month)

# Preview cleaned data
glimpse(snp)
head(snp)

```


```{r}
unemployment = unemployment |>
  pivot_longer(
    cols = -Year,
    names_to = "month",
    values_to = "unemployment"
  ) |>
  mutate(
    year  = Year,
    # standardize month abbreviations to full names
    month = recode(month,
                   Jan = "January", Feb = "February", Mar = "March",
                   Apr = "April",   May = "May",      Jun = "June",
                   Jul = "July",    Aug = "August",   Sep = "September",
                   Oct = "October", Nov = "November", Dec = "December"),
    month = factor(month, levels = month.name),
    unemployment = as.numeric(unemployment)
  ) |>
  select(year, month, unemployment) |>
  arrange(year, month)

# Preview cleaned unemployment data
glimpse(unemployment)
head(unemployment)
```

```{r}
merged = pols_month |>
  left_join(snp, by = c("year", "month")) |>
  left_join(unemployment, by = c("year", "month"))

# Quick summary
dim(merged)
range(merged$year)
names(merged)

```

The **`pols_month`** dataset provides monthly data, including the number of national politicians by party affiliation and an indicator of the president’s party (Democrat or Republican). The **`snp`** dataset records closing values of the S&P stock index on a monthly basis, giving a financial measure of U.S. market performance. The **`unemployment`** dataset contains monthly unemployment rates across the U.S. economy.  

After cleaning and merging these three sources, the resulting dataset contains information on **politics, markets, and the economy** in one place. The merged data frame has `r dim(merged)[1]` rows and `r dim(merged)[2]` columns, covering the years from `r min(merged$year)` through `r max(merged$year)`. Key variables include `year`, `month`, `president`, `close` (S&P closing price), and `unemployment`. This unified dataset allows for examining relationships between political events, stock market fluctuations, and unemployment trends across decades.  


```{r}
# save the merged result for reference
write_csv(merged, "data/merged_pols_snp_unemployment.csv")
```

### Problem 2

```{r}
library(readxl)
library(janitor)
trash_path = "data/202509 Trash Wheel Collection Data.xlsx" 
```

```{r}
read_trash <- function(sheet_name, wheel_label) {
  read_excel(trash_path, sheet = sheet_name, skip = 1) |>
    clean_names() |>
    # keep only dumpster-specific rows (omit notes / figures)
    filter(!is.na(dumpster)) |>
    # standardize types and add identifier
    mutate(
      month = as.character(month),
      year  = as.integer(year),
      trash_wheel = wheel_label
    ) |>
    # round sports_balls to int if the column exists on that sheet
    mutate(across(any_of("sports_balls"), ~ as.integer(round(.x)))) |>
    # drop any columns that are entirely NA (leftover “notes” columns after clean_names)
    select(where(~ !all(is.na(.x))))
}

mr   <- read_trash("Mr. Trash Wheel", "Mr. Trash Wheel")
prof <- read_trash("Professor Trash Wheel", "Professor Trash Wheel")
gwyn <- read_trash("Gwynns Falls Trash Wheel", "Gwynnda")

# combine all three into one tidy dataset
trash_all <- bind_rows(mr, prof, gwyn)

```

```{r}
n_obs   <- nrow(trash_all)
n_vars  <- ncol(trash_all)
year_lo <- min(trash_all$year, na.rm = TRUE)
year_hi <- max(trash_all$year, na.rm = TRUE)

# summaries
prof_total_weight <- prof |>
  summarise(total_weight_tons = sum(weight_tons, na.rm = TRUE)) |>
  pull(total_weight_tons)

gwyn_june22_cigs <- gwyn |>
  filter(year == 2022, month == "June") |>
  summarise(total_cigs = sum(cigarette_butts, na.rm = TRUE)) |>
  pull(total_cigs)

```

The **`Mr. Trash Wheel`** dataset provides per-dumpster collection records (by month and year), including weight and volume of trash removed and counts of common debris (e.g., plastic bottles, polystyrene, cigarette butts). The **`Professor Trash Wheel`** dataset contains the same types of measures for a different installation, recorded with the same structure. The **`Gwynnda (Gwynns Falls Trash Wheel)`** dataset likewise reports per-dumpster totals for weight, volume, and itemized debris counts.  

After cleaning and combining these three sources, the resulting dataset contains information on **trash removal activity across multiple Trash Wheels** in one place. The merged data frame has **`r dim(trash_all)[1]`** rows and **`r dim(trash_all)[2]`** columns, covering the years from **`r min(trash_all$year, na.rm = TRUE)`** through **`r max(trash_all$year, na.rm = TRUE)`**. Key variables include `trash_wheel` (source identifier), `dumpster`, `month`, `year`, `date`, `weight_tons`, `volume_cubic_yards`, `plastic_bottles`, `polystyrene`, `cigarette_butts`, `glass_bottles`, `plastic_bags`, `wrappers`, `sports_balls` (where available), and `homes_powered`. 


```{r}
# save merged
write_csv(trash_all, "data/merged_trash_wheels.csv")
```


### Problem 3

```{r}
library(lubridate)
library(stringr)
zip_codes = read_csv("data/zillow_data/Zip Codes.csv")
zori = read_csv("data/zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv")

zip_codes = zip_codes |> clean_names()
zori = zori |> clean_names()
```

```{r}
# County -> Borough map
county_to_borough = c(
  "Bronx"    = "Bronx",
  "Kings"    = "Brooklyn",
  "New York" = "Manhattan",
  "Queens"   = "Queens",
  "Richmond" = "Staten Island"
)

zip_tbl = zip_codes |>
  transmute(
    zip          = str_pad(as.character(zip_code), width = 5, pad = "0"),
    county       = county,
    borough      = recode(county, !!!county_to_borough),
    neighborhood = neighborhood
  ) |>
  mutate(
    neighborhood = str_squish(neighborhood),   # trim + collapse multiple spaces
    neighborhood = na_if(neighborhood, "")     # turn blanks into NA
  ) |>
  distinct() |>
  arrange(borough, neighborhood, zip)
```

```{r}
# Detect monthly columns whether they look like "2015-01-31" or "x2015_01_31"
date_cols = names(zori) |> keep(~ str_detect(.x, "^\\d{4}-\\d{2}-\\d{2}$"))
if (length(date_cols) == 0) {
  date_cols = names(zori) |> keep(~ str_detect(.x, "^(x)?\\d{4}[_-]\\d{2}[_-]\\d{2}$"))
}
stopifnot(length(date_cols) > 0)

name_to_date = function(s) {
  s |>
    str_remove("^x") |>          # drop leading 'x' if present
    str_replace_all("_", "-") |> 
    ymd(quiet = TRUE)
}

zori_long = zori |>
  pivot_longer(
    cols      = all_of(date_cols),
    names_to  = "date_name",
    values_to = "zori"
  ) |>
  mutate(
    zip   = str_pad(as.character(region_name), width = 5, pad = "0"),
    date  = name_to_date(date_name),
    year  = year(date),
    month = month(date)
  ) |>
  select(zip, city, state_name, date, year, month, zori) |>
  arrange(zip, date)
```

```{r}
zip_tbl_uni = zip_tbl |>
  group_by(zip) |>
  summarise(
    borough      = dplyr::first(na.omit(borough)),
    county       = dplyr::first(na.omit(county)),
    neighborhood = paste(sort(unique(na.omit(neighborhood))), collapse = "; "),
    .groups = "drop"
)

# then join with zip_tbl_uni instead of zip_tbl
nyc_tidy = zori_long |>
  left_join(zip_tbl_uni, by = "zip") |>
  relocate(zip, borough, county, neighborhood, city, state_name,
           date, year, month, zori) |>
  arrange(borough, neighborhood, zip, date)

write_csv(nyc_tidy, "data/nyc_zori_zip_tidy.csv")
```

```{r}
# ZIPs present in the ZIP file but NOT in Zillow
zips_in_zipfile = unique(zip_tbl$zip)
zips_in_zillow  = str_pad(as.character(zori$region_name), 5, pad = "0")
zips_missing_vec = setdiff(zips_in_zipfile, zips_in_zillow)

zips_missing_tbl = tibble(zip = zips_missing_vec) |>
  left_join(zip_tbl, by = "zip") |>
  arrange(borough, neighborhood, zip)

write_csv(zips_missing_tbl, "data/zips_missing_in_zillow.csv")

# small sample for inline text
examples_missing = zips_missing_tbl |> slice_head(n = 15)
```

```{r}
# Compare Jan 2021 vs Jan 2020 (only where both exist)
jan_2020 = nyc_tidy |>
  filter(date == as.Date("2020-01-31")) |>
  select(zip, zori_2020_01 = zori)

jan_2021 = nyc_tidy |>
  filter(date == as.Date("2021-01-31")) |>
  select(zip, zori_2021_01 = zori)

delta_2021_vs_2020 = jan_2020 |>
  inner_join(jan_2021, by = "zip") |>
  mutate(change_2021_minus_2020 = zori_2021_01 - zori_2020_01) |>
  left_join(select(zip_tbl, zip, borough, neighborhood), by = "zip") |>
  relocate(zip, borough, neighborhood, zori_2020_01, zori_2021_01, change_2021_minus_2020)

top10_drop = delta_2021_vs_2020 |>
  arrange(change_2021_minus_2020) |>
  slice_head(n = 10) |>
  mutate(
    Jan_2020 = round(zori_2020_01),
    Jan_2021 = round(zori_2021_01),
    Change_2021_minus_2020 = round(change_2021_minus_2020)
  ) |>
  select(zip, borough, neighborhood, Jan_2020, Jan_2021, Change_2021_minus_2020)

write_csv(top10_drop, "data/nyc_top10_drop_2020_to_2021.csv")

top10_drop
```

```{r}
# counts for write-up
n_obs  = nrow(nyc_tidy)
n_zip  = n_distinct(nyc_tidy$zip)
# ignore empty strings for neighborhood counts
n_nbhd = nyc_tidy |>
  filter(neighborhood != "", neighborhood != " ") |>
  distinct(neighborhood) |>
  nrow()
```



The **ZIP code dataset** lists NYC ZIPs and their associated **county (borough) and neighborhood** names; this provides the geographic bridge to attach borough/neighborhood context to rental prices. The **Zillow ZORI dataset** provides **monthly rental price indices** by ZIP.

After importing, cleaning, and merging, the resulting tidy dataset contains **`r n_obs`** observations (each row is **ZIP × month**), with **`r n_zip`** unique ZIP codes and **`r n_nbhd`** unique neighborhoods. Key variables include `zip`, `borough`, `neighborhood`, `date` (plus `year`, `month`), and `zori` (Zillow Observed Rent Index).

There are **`r nrow(zips_missing_tbl)`** ZIP codes in the ZIP file that do not appear in Zillow (saved to file). Examples include **`r paste(examples_missing$zip, collapse = ", ")`**. These are commonly **special-use or non-residential** ZIPs (e.g., PO boxes, single-building/commercial ZIPs) or areas with **insufficient rental inventory**, so Zillow omits them.

To assess pandemic-era changes, we compared **January 2021 vs January 2020** ZORI for ZIPs with both months available and list the **10 largest drops** in the table above. Declines cluster in core neighborhoods (notably in Manhattan), consistent with early-pandemic rental dynamics.



